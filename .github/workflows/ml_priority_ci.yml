name: priority-model-ci

on:
  workflow_dispatch:
  push:
    paths:
      - "ml_prioritization_dashboard/**"
      - ".github/workflows/ml_priority_ci.yml"

env:
  GCP_PROJECT: boston311-mlops
  BQ_LOCATION: US
  MODEL_REGISTRY_BUCKET: boston311-ml-model-registry
  TRAIN_FEATURE_TABLE: tbl_train_features

jobs:
  priority-model-ci:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r ml_prioritization_dashboard/requirements.txt

      - name: Write BigQuery RO service account key
        env:
          GCP_SA_KEY: ${{ secrets.GCP_SA_KEY }}
        run: |
          mkdir -p secrets
          # Write the JSON from the GitHub secret into the file
          printf '%s' "${GCP_SA_KEY}" > secrets/bq-dashboard-ro.json

      - name: Train & evaluate priority model (with rollback + registry push)
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          MODEL_REGISTRY_BUCKET: ${{ env.MODEL_REGISTRY_BUCKET }}
          TRAIN_FEATURE_TABLE: ${{ env.TRAIN_FEATURE_TABLE }}
        run: |
          python ml_prioritization_dashboard/train_priority_xgb.py

      - name: Core metric gates (test ROC/PR/F1)
        run: |
          python - << 'EOF'
          import json, pathlib, sys

          model_dir = pathlib.Path("ml_prioritization_dashboard/models")
          report_path = model_dir / "model_report.json"

          with open(report_path, "r") as f:
              r = json.load(f)

          test_pr_auc = r.get("test_pr_auc")
          test_roc_auc = r.get("test_roc_auc")
          test_f1 = r.get("test_f1")

          print(f"test_pr_auc={test_pr_auc}, test_roc_auc={test_roc_auc}, test_f1={test_f1}")

          ok = True

          thr_pr = 0.97
          thr_roc = 0.84
          thr_f1 = 0.93

          if test_pr_auc is None or test_pr_auc < thr_pr:
              print(f"FAIL: test_pr_auc below threshold {thr_pr}")
              ok = False
          if test_roc_auc is None or test_roc_auc < thr_roc:
              print(f"FAIL: test_roc_auc below threshold {thr_roc}")
              ok = False
          if test_f1 is None or test_f1 < thr_f1:
              print(f"FAIL: test_f1 below threshold {thr_f1}")
              ok = False

          if not ok:
              sys.exit(1)
          EOF

      - name: Run bias analysis
        env:
          GCP_PROJECT: ${{ env.GCP_PROJECT }}
          BQ_LOCATION: ${{ env.BQ_LOCATION }}
          TRAIN_FEATURE_TABLE: ${{ env.TRAIN_FEATURE_TABLE }}
        run: |
          python ml_prioritization_dashboard/bias_check.py

      - name: Inspect bias gaps (soft check â€“ logs only)
        run: |
          python - << 'EOF'
          import json, pathlib

          model_dir = pathlib.Path("ml_prioritization_dashboard/models")
          bias_path = model_dir / "bias_report.json"

          with open(bias_path, "r") as f:
              bias = json.load(f)

          # Expected *_gap keys (produced by bias_check.py)
          expected_keys = [
              "neighborhood_accuracy_gap",
              "neighborhood_precision_gap",
              "neighborhood_recall_gap",
              "neighborhood_f1_gap",
              "neighborhood_roc_auc_gap",
              "neighborhood_pr_auc_gap",
              "department_accuracy_gap",
              "department_precision_gap",
              "department_recall_gap",
              "department_f1_gap",
              "department_roc_auc_gap",
              "department_pr_auc_gap",
              "reason_accuracy_gap",
              "reason_precision_gap",
              "reason_recall_gap",
              "reason_f1_gap",
              "reason_roc_auc_gap",
              "reason_pr_auc_gap",
          ]

          allowed = 0.20  # soft reference, not a hard gate here

          missing = [k for k in expected_keys if k not in bias]
          if missing:
              print("WARN: Some *_gap keys missing from bias_report.json:", ", ".join(missing))

          for key in expected_keys:
              val = bias.get(key)
              print(f"{key}={val}")
              if isinstance(val, (int, float)):
                  if val > allowed:
                      print(f"  -> Above soft reference threshold {allowed:.2f} (logged only, CI not blocked).")

          print("Bias gaps inspection complete (soft check).")
          EOF

      - name: Send notification email
        if: always()
        uses: dawidd6/action-send-mail@v6
        with:
          server_address: smtp.gmail.com
          server_port: 587
          secure: false
          username: ${{ secrets.MAIL_USERNAME }}
          password: ${{ secrets.MAIL_PASSWORD }}
          subject: "[boston-311-ai-system] Priority model CI run - ${{ job.status }}"
          to: "aidevadarshini2002@gmail.com, harishvtcp@gmail.com"
          from: "aidevadarshini2002@gmail.com"
          body: |
            GitHub Actions run for boston-311-ai-system: Train, validate & bias-check priority model
            Status: ${{ job.status }}
            Run URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}

